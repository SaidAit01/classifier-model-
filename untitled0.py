# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gn3Jz8WuUgj-Q4Zl0sLaRHFXQGe5N0IR
"""

#import packages
import pandas as pd
import numpy as np
#import sklearn which is a library for ML that provideds algorithms and tools for ML tasks such as classification and regression.
from sklearn.model_selection import train_test_split
# We use sklearn.feature_extraction module that is used to convert a collection of text documents into a matrix of token counts.
#CountVectoriser transforms data into numerical respresentation.
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

#imprt dataset
from google.colab import files
uploaded = files.upload()

#import data
spam_df = pd.read_csv('spam.csv', encoding = 'latin-1')
spam_df.head()

#inspect data
spam_df.groupby('Category').describe()

# Turn the category data into numerical data, and create a new column called spam
spam_df['spam'] = spam_df['Category'].apply(lambda x: 1 if x=='spam' else 0)
spam_df.head()

#create train/test split
x_train, x_test, y_train, y_test = train_test_split(spam_df.Message, spam_df.spam, test_size = 0.25)

x_train.describe()

# Find word count and store data as a matrix
cv = CountVectorizer()
x_train_count = cv.fit_transform(x_train.values)

x_train_count

x_train_count.toarray()

#Train model
model = MultinomialNB()
model.fit(x_train_count, y_train)

#pre-test ham
email_ham =['hi buy clothes']
email_ham_count = cv.transform(email_ham)
model.predict(email_ham_count)

#pre-test spam
email_spam = ['Earn free credits with Referrals']
email_spam_count = cv.transform(email_spam)
model.predict(email_spam_count)

#test model
x_test_count = cv.transform(x_test)
model.score(x_test_count, y_test)